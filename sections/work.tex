\section{Travail effectué}

\subsection{Objectifs du stage}

L'évolution des pratiques de développement logiciel dans le domaine du calcul
scientifique a été marquée ces dernières années par l'adoption généralisée des
approches GitOps. Ces méthodologies, qui s'appuient sur des systèmes de contrôle
de version et d'intégration continue, permettent d'automatiser les processus de
test, de validation et de déploiement des logiciels. L'arrivée de plateformes
comme GitLab a considérablement facilité la mise en œuvre de ces pratiques en
proposant des outils intégrés pour orchestrer l'ensemble du cycle de vie du
développement logiciel.

\bigskip

Dans ce contexte, la Direction de la Recherche Technologique (DRT), une autre
direction opérationnelle du CEA, a lancé via son laboratoire DeepLab une instance
GitLab privée, interne au CEA. Cette infrastructure offre aux équipes de
recherche un environnement sécurisé pour héberger leur code source et mettre en
place des pipelines d'intégration continue adaptés aux exigences de sécurité de
l'institution.

\bigskip

Cependant, TRUST, le logiciel de thermohydraulique développé par le CEA depuis
plus de vingt ans, n'a pas bénéficié de ces évolutions récentes. Son code source,
bien que continuellement amélioré sur le plan scientifique, accuse un retard
significatif en matière de pratiques GitOps. Cette situation s'explique en partie
par l'historique du projet et la complexité de ses contraintes techniques. En
effet, TRUST doit être testé sur de multiples architectures matérielles afin de
garantir sa portabilité : architectures CPU traditionnelles, architectures
hybrides CPU-GPU, supercalculateurs, et différents systèmes d'exploitation. Ces
tests de portabilité sont essentiels pour assurer que le logiciel fonctionne de
manière fiable dans tous les environnements où il est déployé.

\bigskip

Au-delà du code source de TRUST lui-même, l'écosystème du logiciel comprend
également les Baltiks, un ensemble de projets satellites qui dépendent de TRUST
et qui étendent ses fonctionnalités pour des applications spécifiques. Ces
projets nécessitent eux aussi d'être testés régulièrement pour détecter
d'éventuelles régressions introduites par les évolutions de TRUST.

\bigskip

L'objectif principal de mon stage est donc de concevoir et de déployer une
nouvelle infrastructure d'intégration continue pour TRUST et ses projets associés.
Cette CI doit permettre de tester automatiquement le code source à chaque
modification, de valider la portabilité sur différentes architectures, de vérifier
le bon fonctionnement sur GPU, et d'assurer la non-régression des Baltiks. Ce
travail s'inscrit pleinement dans la stratégie de modernisation des outils de
simulation du CEA et dans l'adaptation aux nouvelles pratiques de développement
logiciel.

\subsection{Infrastructure d'intégration continue existante}

Avant le lancement de ce projet, TRUST disposait déjà d'un système de tests
automatisés, bien que celui-ci ne repose pas sur les standards modernes
d'intégration continue. Ce système, baptisé l'Atelier, est constitué d'un
ensemble de scripts Bash développés au fil des années par les équipes du
laboratoire. Ces scripts s'exécutent quotidiennement sur les stations de travail
des chercheurs et ingénieurs du LCAN durant la nuit, profitant ainsi des périodes
d'inactivité des machines pour réaliser les tests sans perturber les activités de
développement.

\bigskip

L'Atelier orchestre l'exécution d'une batterie de tests unitaires et d'intégration
qui permettent de détecter les régressions introduites par les modifications du
code. Avant chaque release officielle de TRUST, des tests plus exhaustifs et plus
longs sont lancés afin de garantir la stabilité de la version publiée. Ces tests
comprennent notamment des simulations complètes qui peuvent nécessiter plusieurs
heures de calcul et qui sollicitent intensivement les ressources matérielles
disponibles.

\bigskip

Bien que l'Atelier ait rendu service au projet pendant de nombreuses années, ce
système présente plusieurs limitations importantes. Premièrement, sa dépendance
aux machines personnelles des chercheurs pose des problèmes de disponibilité et
de reproductibilité : si une machine est éteinte ou indisponible, les tests ne
sont pas exécutés. Deuxièmement, l'absence de centralisation rend difficile la
supervision de l'ensemble des tests et la détection rapide des problèmes.
Troisièmement, l'architecture basée sur des scripts Bash devient de plus en plus
difficile à maintenir et à faire évoluer à mesure que les besoins se complexifient.
Enfin, ce système ne permet pas d'intégrer facilement les nouvelles pratiques de
développement collaboratif, notamment les tests automatiques déclenchés à chaque
commit ou lors de l'ouverture de merge requests.

\bigskip

Ces constats ont motivé la décision de concevoir une nouvelle infrastructure
d'intégration continue, plus moderne, plus robuste et mieux adaptée aux besoins
actuels du projet TRUST.

\subsection{Infrastructure développée}

Mon travail a consisté à concevoir et déployer une infrastructure complète
d'intégration continue pour TRUST, tirant parti des capacités offertes par GitLab
CI/CD. Cette nouvelle infrastructure repose sur des pipelines automatisés qui se
déclenchent à chaque modification du code source et qui orchestrent l'exécution
de différentes catégories de tests.

\bigskip

La CI développée couvre plusieurs axes de validation. Premièrement, elle
implémente des tests de portabilité permettant de vérifier que TRUST compile et
s'exécute correctement sur diverses architectures matérielles et systèmes d'
exploitation. Deuxièmement, elle intègre des tests spécifiques pour les
architectures GPU, essentiels dans le contexte du passage aux supercalculateurs
exascale. Troisièmement, elle assure la validation des Baltiks en testant
automatiquement ces projets satellites contre la dernière version de TRUST,
détectant ainsi immédiatement toute incompatibilité introduite par les évolutions
du code principal.

\bigskip

La mise en œuvre de cette CI a nécessité le déploiement de runners GitLab sur l'
infrastructure physique du laboratoire. Cette étape s'est révélée particulièrement
complexe en raison des contraintes de sécurité strictes imposées par le CEA. En
effet, l'ensemble de l'infrastructure doit fonctionner en mode rootless, c'est-à-
dire sans privilèges administrateur, afin de minimiser les risques de sécurité.
Cette contrainte a imposé des choix techniques spécifiques et a nécessité de
résoudre plusieurs problèmes d'architecture réseau et de gestion des conteneurs.

\bigskip

L'infrastructure déployée s'appuie sur du matériel informatique de haute
performance mis à disposition par le laboratoire, comprenant notamment des
serveurs rackés et des stations de travail équipées de GPU consumer puissants.
Cette puissance de calcul permet d'exécuter rapidement les tests, même les plus
intensifs, et de fournir un retour rapide aux développeurs.

\bigskip

Au-delà de l'infrastructure technique, j'ai également produit la documentation
nécessaire à la maintenance et à l'évolution de cette CI, ainsi que des guides
d'utilisation pour les développeurs de TRUST. Cette documentation est essentielle
pour assurer la pérennité du système et faciliter son appropriation par l'équipe.

\subsection{Ressources et accompagnement}

La réalisation de ce projet s'est effectuée avec le soutien de mes deux
encadrants, Rémi Bougeois et Adrien Bruneton, qui m'ont accompagné tout au long
du stage en apportant leur expertise technique et leur connaissance approfondie
de l'écosystème TRUST. Leur disponibilité et leurs conseils ont été précieux
pour orienter mes choix techniques et résoudre les problèmes complexes rencontrés.

\bigskip

Au-delà de mes encadrants directs, j'ai pu m'appuyer sur l'ensemble de l'équipe
du LCAN, dont l'expérience collective en matière de calcul scientifique et de
développement logiciel a constitué une ressource inestimable. Les échanges
réguliers avec les chercheurs et ingénieurs du laboratoire m'ont permis de mieux
comprendre les besoins opérationnels et les contraintes spécifiques du domaine.

\bigskip

Pour les aspects techniques plus spécialisés, notamment concernant l'
infrastructure réseau et les questions de sécurité informatique, j'ai bénéficié
du support de l'équipe RSI (Réseaux et Systèmes d'Information) de l'ISAS. Cette
équipe, joignable via un système de tickets, a apporté son expertise pour
résoudre les problèmes d'infrastructure et valider la conformité de mes
développements avec les politiques de sécurité du CEA.

\bigskip

Enfin, j'ai disposé d'un environnement matériel particulièrement favorable, avec
un accès à une infrastructure physique puissante comprenant des serveurs rackés
dédiés, des stations de travail équipées de GPU consumer de dernière génération,
et un accès à différents environnements de calcul permettant de tester la
portabilité du code dans des conditions réalistes. Cette richesse en ressources
matérielles a été un atout majeur pour mener à bien les missions qui m'ont été
confiées.

\subsection{Compte-rendu d'activité}

\subsubsection{Axes d'étude et de recherche choisis}

Les axes d'étude et de développement se sont appuyés sur un cadre initial fourni par mes encadrants. Les principaux axes de travail sont les suivants :

\medskip
\begin{enumerate}
\item Documentation et appropriation de l'écosystème TRUST. L'étude s'est concentrée sur la compréhension du fonctionnement de TRUST, de son processus de compilation et de son écosystème de tests existants (l'Atelier). Réalisation des tutoriels utilisateurs et analyse des scripts Bash de l'infrastructure existante.
\medskip
\item Étude des technologies d'intégration continue et de conteneurisation. Exploration approfondie de GitLab CI/CD, des pipelines et des bonnes pratiques DevOps. Étude comparative des solutions de conteneurisation (Docker vs Podman) et des architectures de déploiement (Docker Compose, Usernetes, scripts personnalisés).
\medskip
\item Exploration des contraintes de sécurité CEA. Compréhension des exigences de sécurité imposant un fonctionnement en mode rootless. Étude des implications sur l'architecture réseau (absence d'IPv4 forwarding, utilisation de slirp4netns) et sur la gestion des conteneurs.
\medskip
\item Lecture de la documentation GitLab CI/CD et des runners. Étude approfondie des mécanismes de cache, des artifacts, des stratégies de parallélisation et des templates réutilisables. Exploration des patterns de configuration avancés (includes, anchors, matrices).
\medskip
\end{enumerate}
\medskip

Ces activités de recherche et d'appropriation ont impliqué une phase intensive de documentation pendant les premières semaines du stage. Le livrable associé à ces travaux est une infrastructure complète documentée et déployée.

\subsubsection{Déroulement concret des études, expérimentations et mises au point}

\subsubsubsection{Chronologie du stage}

Le stage s'est déroulé sur une période de six mois, selon la chronologie suivante :

\medskip
\begin{itemize}
\item[•] \textbf{Semaines 1--2} : Arrivée au CEA, formalités administratives et mesures de sécurité. Découverte de l'environnement TRUST, réalisation des tutoriels utilisateurs.
\item[•] \textbf{Semaines 3--5} : Premières tentatives de compilation de TRUST dans des conteneurs Docker. Déploiement de Docker en mode rootless sur les serveurs du laboratoire.
\item[•] \textbf{Semaines 6--8} : Migration de TRUST et de ses dépendances (ExternalPackages) vers GitLab. Exploration de différentes infrastructures et logiciels de CI/CD.
\item[•] \textbf{Semaines 9--12} : Mise en place des runners GitLab via Docker Compose. Déploiement de la stack de monitoring (Prometheus, Grafana).
\item[•] \textbf{Semaines 13--16} : Développement de la CI/CD pour les tests CPU sur multiples distributions Linux. Configuration des runners GPU et intégration des tests GPU.
\item[•] \textbf{Semaines 17--20} : Déploiement du serveur de stockage distribué (MinIO) pour optimiser le partage de cache entre runners. Intégration des dépôts Baltiks dans la pipeline.
\item[•] \textbf{Semaines 21--24} : Finalisation de la documentation technique, guides utilisateurs et de maintenance. Tests de validation finale de l'infrastructure complète.
\end{itemize}

\subsubsubsection{Déploiement de Docker en mode rootless sur l'infrastructure du laboratoire}

Le premier défi technique a consisté à déployer Docker en mode rootless sur les serveurs du laboratoire. Ce choix s'est imposé pour respecter les contraintes de sécurité strictes du CEA, qui interdisent l'utilisation de privilèges administrateur pour les services de développement.

\bigskip

Le processus de déploiement a nécessité de nombreuses interactions avec l'équipe RSI (Réseaux et Systèmes d'Information) de l'ISAS afin d'obtenir les configurations nécessaires, notamment l'attribution de plages de subuid et subgid pour chaque utilisateur devant exécuter Docker. Ces identifiants subordonnés sont essentiels au fonctionnement du mode rootless, car ils permettent de mapper les utilisateurs conteneurisés à des plages d'UID non privilégiées sur l'hôte.

\bigskip

Plusieurs obstacles techniques ont émergé lors du déploiement. L'absence d'IPv4 forwarding sur les serveurs a rendu impossible l'utilisation du bridge réseau standard de Docker. La solution retenue a été d'utiliser slirp4netns, un outil qui implémente un réseau en espace utilisateur permettant aux conteneurs de communiquer sans nécessiter de privilèges réseau. Cette configuration particulière a été documentée dans les fichiers de configuration Docker du projet.

\bigskip

Un autre défi concernait les images de base pour TRUST. Les premiers essais avec des images standards se sont heurtés à deux problèmes : d'une part, TRUST refuse de compiler en tant que root pour des raisons de sécurité, nécessitant la création d'utilisateurs non privilégiés dans les conteneurs ; d'autre part, les dépendances de TRUST (regroupées dans le paquet ExternalPackages) représentent plusieurs gigaoctets de données, rendant les images initiales excessivement volumineuses (plus de 5 Go). Une refonte complète de la stratégie de construction des images a permis de réduire significativement leur taille en séparant les dépendances système des artefacts de compilation.

\bigskip

Le choix entre Docker et Podman a également été étudié. Bien que Podman soit conceptuellement plus adapté à un environnement rootless, Docker a été retenu pour sa maturité, sa documentation plus extensive et sa meilleure intégration avec GitLab Runner.

\subsubsubsection{Migration de TRUST et de ses dépendances vers GitLab}

Bien que le code source principal de TRUST ait déjà été migré vers GitLab au début du stage, le dépôt ExternalPackages, contenant l'ensemble des dépendances de TRUST sous forme d'archives compressées, posait un problème majeur. Ce dépôt est nécessaire car TRUST doit pouvoir se compiler en environnement isolé sans accès Internet, notamment dans les zones sécurisées du CEA. Il contient plusieurs dizaines de gigaoctets d'archives (fichiers .tar.gz des bibliothèques tierces).

\bigskip

Les premiers essais de migration directe se sont heurtés aux limitations de taille imposées par le serveur GitLab. Plusieurs tentatives de contournement par l'envoi fragmenté des données se sont révélées infructueuses et chronophages.

\bigskip

La solution retenue a été d'utiliser Git LFS (Large File Storage) pour gérer les archives volumineuses. Cette approche n'avait pas été envisagée initialement afin de maintenir une transition aussi fluide que possible pour les développeurs, mais elle s'est finalement imposée comme la seule option viable. La migration a nécessité une réécriture complète de l'historique Git du dépôt ExternalPackages pour intégrer Git LFS de manière transparente, en préservant l'historique des commits.

\bigskip

De nombreux tests ont été effectués pour s'assurer que l'accès aux dépendances restait fonctionnel dans tous les environnements d'utilisation, notamment pour les workflows existants des développeurs. L'ensemble de ces travaux est documenté dans la pull-request de migration et dans le guide de maintenance du dépôt.

\subsubsubsection{Déploiement de l'infrastructure via Docker Compose}

Le choix de Docker Compose pour orchestrer l'infrastructure de CI/CD s'est imposé après l'évaluation de plusieurs alternatives. Docker Compose offre un équilibre optimal entre flexibilité et simplicité : il est suffisamment permissif pour permettre des configurations avancées tout en restant accessible aux membres de l'équipe qui devront maintenir l'infrastructure.

\bigskip

D'autres solutions ont été considérées, notamment Usernetes (une distribution Kubernetes en mode utilisateur) et l'utilisation de scripts shell personnalisés pour déployer les conteneurs. Usernetes a été écarté en raison de sa complexité excessive pour les besoins du projet, tandis que l'approche par scripts aurait posé des problèmes de maintenabilité à long terme.

\bigskip

L'infrastructure déployée via Docker Compose comprend deux composants principaux : les runners GitLab proprement dits, et une stack de monitoring complète. Cette dernière repose sur Prometheus pour la collecte et le stockage des métriques, Grafana pour la visualisation, Node Exporter pour les métriques système de l'hôte, et cAdvisor pour les métriques des conteneurs.

\bigskip

\setlength{\intextsep}{0pt}%
\begin{wrapfigure}{r}{0.5\textwidth}
\vspace{-1em}
\begin{itemize}
\item[•] \textbf{Prometheus} (port 9090) : collecte et stockage des métriques
\item[•] \textbf{Grafana} (port 3000) : visualisation via tableaux de bord
\item[•] \textbf{Node Exporter} (port 9100) : métriques système de l'hôte
\item[•] \textbf{cAdvisor} (port 8080) : métriques des conteneurs
\end{itemize}
\vspace{-1em}
\end{wrapfigure}

La configuration a été conçue pour exposer les métriques de manière structurée, permettant une surveillance en temps réel de l'état des runners, de la charge système et des performances des jobs CI/CD. Plusieurs tableaux de bord Grafana préconfigurés ont été développés pendant le stage : vue d'ensemble complète de la stack, monitoring détaillé des conteneurs, métriques spécifiques aux runners GitLab et statistiques des jobs, ainsi que le monitoring système de l'hôte (CPU, mémoire, disque, réseau).

\bigskip

Cette infrastructure de monitoring s'est révélée essentielle pour identifier les goulots d'étranglement et optimiser la configuration des runners au fil du stage. L'ensemble de la configuration Docker Compose est documentée dans le dépôt du projet, avec des guides de déploiement et de maintenance.

\clearpage
\subsubsubsection{Conception et implémentation de la CI/CD pour les tests CPU}

La conception de la pipeline d'intégration continue a constitué le cœur technique du stage. L'objectif était de créer une infrastructure capable de tester automatiquement TRUST sur l'ensemble des distributions Linux supportées, en parallélisant au maximum les jobs tout en optimisant l'utilisation des ressources.

\bigskip

La pipeline s'articule autour de six stages principaux :

\medskip
\begin{enumerate}
\item \texttt{.pre} : détermination automatique de la branche ExternalPackages à utiliser
\item \texttt{setup} : clonage et mise à jour du dépôt ExternalPackages
\item \texttt{configure} : exécution de \texttt{./configure} pour chaque distribution
\item \texttt{build} : compilation de TRUST
\item \texttt{test} : exécution de la suite de tests
\item \texttt{.post} : sessions de debug interactives (manuelles)
\end{enumerate}
\medskip

Un système de nommage cohérent a été adopté pour les jobs : \texttt{<stage>:<config\_name>}, facilitant l'identification rapide des problèmes (exemples : \texttt{configure:cpu\_fedora40}, \texttt{build:cpu\_ubuntu22}, \texttt{test:cpu\_ubi9}).

\bigskip

\setlength{\intextsep}{0pt}%
\setlength{\extrarowheight}{0.15cm}
\begin{wrapfigure}{l}{0.55\textwidth}
\vspace{-0.5em}
{\footnotesize
\begin{tabular}{|l|l|l|}
\hline
Distribution & Image Docker & Gestionnaire \\
\hline
Fedora 40 & \texttt{fedora:40} & dnf \\
\hline
Rocky Linux 9 & \texttt{rockylinux:9} & dnf \\
\hline
CentOS Stream 9 & \texttt{centos:stream9} & dnf \\
\hline
Ubuntu 22.04 & \texttt{ubuntu:22.04} & apt \\
\hline
UBI 9 & \texttt{redhat/ubi9} & dnf \\
\hline
\end{tabular}
\vspace{-0.5em}
\captionof{table}{Distributions CPU intégrées à la CI}
\label{tab:distros_cpu}}
\end{wrapfigure}

Cinq distributions CPU ont été intégrées (table~\ref{tab:distros_cpu}). Chaque distribution est définie via une ancre YAML contenant tous ses paramètres : image Docker, gestionnaire de paquets, options de configuration, cibles de tests et tags de runners.

\bigskip

\paragraph{Choix architectural : templates vs matrices}

Une décision importante a concerné la structure de la configuration. GitLab CI/CD propose deux approches principales : les matrices (permettant de générer automatiquement des jobs variés à partir d'une définition unique) et les templates réutilisables avec \texttt{include}.

\bigskip

La solution retenue utilise des templates avec \texttt{include}, car elle offre une meilleure lisibilité et une plus grande flexibilité. Chaque distribution est définie dans \texttt{gitlab-ci.yml} puis incluse via un template générique \texttt{build-config.yml} qui génère automatiquement les trois jobs (configure, build, test). Cette approche facilite l'ajout de nouvelles distributions et permet des personnalisations fines par distribution si nécessaire.

\bigskip

\paragraph{Stratégie de cache à deux niveaux}

Un système de cache sophistiqué a été mis en place pour optimiser les temps d'exécution :

\medskip
\begin{itemize}
\item[•] \textbf{Cache ExternalPackages} : clé \texttt{extpkgs-\$\{EXTPKGS\_BRANCH\}}, partagé entre toutes les configurations. Ce cache n'est mis à jour que lorsque le dépôt ExternalPackages change, évitant des clonages répétés coûteux.
\medskip
\item[•] \textbf{Cache de build} : clé \texttt{build-\$\{CONFIG\_NAME\}-\$\{CI\_PIPELINE\_ID\}}, spécifique à chaque configuration et isolé par pipeline. Cette isolation prévient les conflits entre pipelines concurrents.
\end{itemize}

\bigskip

\paragraph{Mécanisme de matching de branches}

Un système intelligent de détection de branches a été implémenté pour ExternalPackages. Lors du job \texttt{determine\_branch} en stage \texttt{.pre}, la pipeline vérifie si une branche du même nom que celle du dépôt principal existe dans ExternalPackages. Si oui, elle est utilisée ; sinon, la branche \texttt{next} est sélectionnée par défaut. Ce mécanisme permet un développement coordonné multi-dépôts, facilitant les évolutions nécessitant des modifications synchronisées de TRUST et de ses dépendances.

\bigskip

\paragraph{Gestion des artefacts}

Les artefacts sont conservés selon leur utilité : logs de configuration et compilation (30 jours), résultats de tests au format JUnit avec listes de tests échoués (30 jours), et fichiers d'environnement indiquant les branches utilisées et le statut du cache (1 jour).

\bigskip

Les jobs utilisent le mot-clé \texttt{needs} pour optimiser la parallélisation, avec \texttt{artifacts: false} lorsque seule la complétion du job importe, réduisant ainsi les transferts inutiles. Cette optimisation s'est révélée particulièrement efficace pour les jobs de test, qui n'ont pas besoin de télécharger les logs de compilation.

\subsubsubsection{Extension de la CI pour les tests GPU}

L'extension de la pipeline aux architectures GPU a nécessité des adaptations spécifiques. Trois configurations GPU ont été ajoutées, basées sur les images NVIDIA CUDA officielles : CUDA 12.4 sur UBI 9, CUDA 12.5 sur UBI 9, et CUDA 12.4 sur Ubuntu 22.04.

\bigskip

Ces configurations utilisent des tags de runners spécifiques (\texttt{["docker", "gpu", "nvidia"]}) pour s'exécuter sur les stations de travail équipées de GPU consumer puissants mis à disposition par le laboratoire. Le passage de l'option \texttt{-cuda} à la commande \texttt{./configure} active le support GPU dans TRUST.

\bigskip

Les jobs GPU partagent la même structure que les jobs CPU (configure, build, test) mais nécessitent des timeouts légèrement plus longs en raison de la complexité accrue des tests. La stratégie de cache reste identique, garantissant que les builds GPU bénéficient également de l'optimisation ExternalPackages. Des tests spécifiques ont été ajoutés pour valider le bon fonctionnement sur GPU, notamment via la cible \texttt{ctest\_optim} qui exécute la suite de tests complète avec accélération GPU.

\subsubsubsection{Serveur de stockage distribué pour le partage de cache}

Afin d'améliorer encore les performances de la CI, un serveur de stockage distribué basé sur MinIO a été déployé. MinIO est un serveur de stockage objet compatible S3, open-source et auto-hébergeable.

\bigskip

Cette infrastructure permet aux runners de partager efficacement leurs caches, notamment le volumineux cache ExternalPackages. Sans ce système, chaque runner devait maintenir sa propre copie locale du cache, entraînant une duplication importante des données et des temps de restauration de cache variables selon le runner sélectionné.

\bigskip

Avec MinIO, le cache est centralisé et accessible via le protocole S3. GitLab CI est configuré pour utiliser ce stockage distribué comme backend de cache, garantissant que tous les runners accèdent à la même source de vérité. Cela se traduit par des temps de restauration de cache plus prévisibles et une utilisation plus efficace de l'espace disque disponible.

\bigskip

Le déploiement de MinIO s'est intégré naturellement dans le Docker Compose existant, avec une configuration adaptée au mode rootless et aux contraintes réseau du CEA. Cette solution s'est révélée particulièrement efficace pour réduire les temps de setup des jobs de 5--10 minutes à moins d'une minute dans le cas où le cache ExternalPackages est déjà présent.

\subsubsubsection{Intégration des dépôts Baltiks}

Les Baltiks constituent des projets satellites de TRUST qui étendent ses fonctionnalités pour des applications spécifiques. Leur intégration dans la CI était essentielle pour détecter automatiquement les régressions introduites par les modifications de TRUST.

\bigskip

Un stage dédié \texttt{baltiks} a été créé, s'exécutant uniquement lors des merge requests pour ne pas surcharger la pipeline des commits de développement quotidien. Deux approches ont été implémentées :

\medskip
\begin{itemize}
\item[•] \textbf{Méthode rapide via \texttt{baltiks-distros.yml}} : permet de tester un Baltik sur toutes les distributions CPU en une seule déclaration \texttt{include}, générant automatiquement cinq jobs (un par distribution).
\medskip
\item[•] \textbf{Méthode personnalisée via \texttt{baltiks-config.yml}} : offre un contrôle fin sur la configuration, permettant de tester un Baltik sur une distribution spécifique avec des options particulières (timeout personnalisé, options de configuration spéciales).
\end{itemize}
\medskip

Le mécanisme de fonctionnement des jobs Baltiks suit cette séquence : (i) récupération du cache de build du job \texttt{test:\$\{base\_config\_name\}} correspondant, (ii) clonage du dépôt Baltik avec le même système de matching de branches que ExternalPackages, (iii) reconfiguration avec les options spécifiées, (iv) recompilation, et (v) exécution des tests du Baltik.

\bigskip

Les résultats sont conservés dans les artefacts pendant 30 jours, incluant les listes de tests échoués et les logs détaillés. Cette approche garantit que tout changement dans TRUST est immédiatement validé contre l'ensemble de son écosystème, réduisant drastiquement le risque de régressions non détectées.

\subsubsubsection{Jobs de debug interactifs}

Deux jobs de debug manuels ont été conçus pour faciliter l'investigation des problèmes :

\medskip
\begin{itemize}
\item[•] \textbf{\texttt{debug:all}} : environnement Fedora 40 avec les caches de plusieurs configurations chargés, idéal pour des investigations comparatives ou lorsque la configuration problématique n'est pas identifiée.
\medskip
\item[•] \textbf{\texttt{debug:config}} : environnement configurable via des variables (\texttt{DEBUG\_IMAGE}, \texttt{CONFIG\_NAME}, \texttt{DEBUG\_WORKER}), permettant de reproduire exactement l'environnement d'un job spécifique, y compris sur GPU.
\end{itemize}
\medskip

Ces jobs lancent un conteneur en mode interactif pendant deux heures, donnant accès à un shell complet. Un script helper (\texttt{./scripts/debug-v2.sh}) simplifie la connexion aux sessions de debug via Docker.

\bigskip

Cette fonctionnalité s'est révélée indispensable lors du développement de la CI pour diagnostiquer les problèmes de configuration et de dépendances sans avoir à modifier constamment les jobs et relancer des pipelines complètes. Elle est également utilisable par les développeurs pour investiguer les échecs de tests dans l'environnement exact où ils se sont produits.

\subsection{Développement, interprétation et critique des résultats}

\subsubsection{Validation de l'infrastructure développée}

L'infrastructure déployée a été validée par plusieurs semaines de tests intensifs. Les points suivants ont été confirmés :

\medskip
\begin{enumerate}
\item \textbf{Reproductibilité} : les pipelines peuvent être relancées avec des résultats identiques, garantissant la fiabilité des tests.
\medskip
\item \textbf{Performance} : le système de cache à deux niveaux réduit significativement les temps d'exécution. Un build complet sans cache prenait initialement 45--60 minutes ; avec cache, ce temps est réduit à 8--12 minutes.
\medskip
\item \textbf{Scalabilité} : l'architecture supporte l'ajout de nouvelles distributions et de nouveaux Baltiks sans modification majeure de la structure. L'ajout d'une nouvelle distribution nécessite moins de 20 lignes de configuration YAML.
\medskip
\item \textbf{Portabilité multi-architecture} : validation du fonctionnement sur CPU (Intel et AMD) et GPU (NVIDIA), confirmant la compatibilité avec l'infrastructure hétérogène du laboratoire.
\medskip
\item \textbf{Intégration développeur} : les retours de l'équipe ont confirmé que la CI s'intègre naturellement dans le workflow de développement, avec des feedbacks rapides sur les merge requests (moins de 30 minutes pour une validation complète CPU).
\end{enumerate}

\subsubsection{Limitations identifiées et perspectives d'amélioration}

Plusieurs limitations ont été identifiées au cours du stage :

\medskip

\paragraph{Support GPU AMD}
Bien que l'infrastructure supporte théoriquement les GPU AMD via ROCm, aucune configuration spécifique n'a été déployée faute de matériel disponible pendant le stage. L'ajout du support AMD MI250 (disponible sur le supercalculateur Adastra) constitue une évolution naturelle, nécessitant principalement l'ajout d'images Docker basées sur ROCm et l'accès à des runners équipés de GPU AMD.

\medskip

\paragraph{Tests sur supercalculateurs}
Les tests intensifs sur architectures multi-nœuds (Topaze, Adastra) n'ont pas encore été intégrés à la CI automatique. Cette intégration nécessiterait de déployer des runners sur ces infrastructures, ce qui pose des défis de sécurité et de gestion des ressources partagées. Une approche par jobs manuels déclenchés avant les releases majeures pourrait constituer un premier pas.

\medskip

\paragraph{Optimisation des temps de tests}
Certaines suites de tests prennent encore plus de deux heures. Une analyse fine permettrait d'identifier les tests les plus longs et de les paralléliser davantage ou de les exécuter de manière conditionnelle (par exemple, uniquement sur la branche principale ou avant les releases).

\medskip

\paragraph{Observabilité avancée}
Bien que Grafana fournisse des métriques système, l'ajout de métriques applicatives spécifiques à TRUST (temps par étape de compilation, couverture de tests, évolution des temps d'exécution dans le temps) enrichirait l'analyse des performances et faciliterait la détection de régressions de performance.

\subsubsection{Comparaison avec l'infrastructure précédente}

\setlength{\intextsep}{0pt}%
\setlength{\extrarowheight}{0.15cm}
\begin{wrapfigure}{r}{0.6\textwidth}
\vspace{-1em}
{\footnotesize
\begin{tabular}{|l|c|c|}
\hline
Critère & L'Atelier & GitLab CI \\
\hline
Centralisation & Non & Oui \\
\hline
Disponibilité & Variable & Garantie \\
\hline
Intégration MR & Non & Oui \\
\hline
Traçabilité & Limitée & Complète \\
\hline
Temps feedback & 12--24h & 30--60 min \\
\hline
Extensibilité & Difficile & Facile \\
\hline
\end{tabular}
\vspace{-0.5em}
\captionof{table}{Comparaison des infrastructures}
\label{tab:comparaison}}
\end{wrapfigure}

Par rapport à l'Atelier (table~\ref{tab:comparaison}), l'infrastructure GitLab CI/CD apporte plusieurs améliorations majeures : centralisation de tous les résultats via l'interface GitLab contre des résultats dispersés sur différentes machines, disponibilité garantie grâce à des runners dédiés indépendants des postes de développeurs, validation automatique sur chaque merge request contre des tests nocturnes déconnectés du workflow, traçabilité complète avec historique des exécutions et artefacts conservés facilitant le diagnostic de régressions anciennes, et extensibilité via quelques lignes de YAML contre modification de scripts Bash complexes.

\bigskip

Cependant, l'Atelier conserve certains avantages, notamment sa simplicité conceptuelle et son indépendance vis-à-vis d'infrastructures externes. Une approche hybride, où l'Atelier continuerait à exécuter les tests les plus lourds durant la nuit pendant que la CI GitLab valide rapidement les merge requests, pourrait être envisagée pour combiner les forces des deux systèmes.

\subsubsection{Bilan et perspectives}

Ce stage a permis de moderniser significativement l'infrastructure de tests de TRUST, alignant le projet sur les pratiques GitOps contemporaines. L'infrastructure développée est désormais opérationnelle, documentée et maintenue par l'équipe du LCAN.

\bigskip

Les perspectives d'évolution incluent :

\medskip
\begin{itemize}
\item[•] Extension du support GPU avec intégration de ROCm pour les architectures AMD.
\item[•] Intégration de tests de performance automatisés avec génération de rapports de régression.
\item[•] Déploiement de runners sur supercalculateurs pour les tests à très grande échelle.
\item[•] Mise en place de dashboards de santé projet (taux de réussite des merge requests, temps moyen de validation, évolution du nombre de tests).
\item[•] Intégration d'outils d'analyse statique de code et de mesure de couverture de tests.
\end{itemize}
\medskip

L'expérience acquise sur les contraintes de sécurité du CEA, la conteneurisation rootless et l'orchestration de pipelines complexes constitue un acquis précieux, transférable à d'autres projets du laboratoire souhaitant moderniser leurs pratiques DevOps.
